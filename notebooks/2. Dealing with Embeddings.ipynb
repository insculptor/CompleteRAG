{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # <center>Creating Embeddings for RAG Pipeline</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we delve into sophisticated methods for enhancing document retrieval capabilities, focusing on embeddings, text chunking, and efficient database setup and insertion. Our goal is to leverage these techniques to improve the performance of a Retriever-Augmented Generation (RAG) System, which combines the power of retrieval from a large corpus with the generative capabilities of a language model.\n",
    "\n",
    "## 1. Embeddings\n",
    "\n",
    "### What is an Embedding and Why We Need Them?\n",
    "Embeddings are dense vector representations of text data that capture the semantic meaning of words, sentences, or documents. By transforming text into vectors in a high-dimensional space, embeddings allow us to perform arithmetic operations on words and documents, facilitating tasks like similarity search, clustering, and classification. They are crucial for enabling the RAG system to efficiently retrieve relevant documents based on the query's semantic content.\n",
    "\n",
    "### Things to Keep in Mind While Creating Embeddings\n",
    "- **Dimensionality**: The choice of dimensionality affects both the granularity of the captured semantics and the computational efficiency.\n",
    "- **Training Data**: The quality and representativeness of the training data determine the embeddings' applicability to various domains.\n",
    "- **Normalization**: Normalizing embeddings can improve the performance of similarity searches.\n",
    "\n",
    "### Strategies for Creating Embeddings\n",
    "- **Pre-trained Models**: Utilizing models pre-trained on large, diverse corpora as a starting point.\n",
    "- **Domain-specific Training**: Fine-tuning pre-trained models on domain-specific data to capture specialized vocabulary and concepts.\n",
    "- **Dimensionality Reduction**: Applying techniques like PCA to reduce the dimensionality of embeddings while preserving semantic relationships.\n",
    "\n",
    "### MTEB Leaderboard\n",
    "The Multilingual Text Embeddings Benchmark (MTEB) leaderboard showcases the performance of various embedding models across multiple languages and tasks, serving as a guide for selecting the best-performing models for specific applications.\n",
    "\n",
    "### Creating Embeddings\n",
    "This section will demonstrate how to generate embeddings from our text data using selected strategies, preparing them for use in our retrieval system.\n",
    "\n",
    "### How Embeddings Impact the Performance of the RAG System\n",
    "Embeddings play a pivotal role in the RAG system by enabling the efficient retrieval of semantically relevant documents. High-quality embeddings can significantly enhance the system's ability to generate accurate and contextually appropriate responses.\n",
    "\n",
    "## 2. Chunking Text\n",
    "\n",
    "### Why We Need Chunks?\n",
    "Chunking helps in managing large documents by breaking them down into manageable pieces, which are more feasible for processing by machine learning models and for retrieval based on specific queries.\n",
    "\n",
    "### Best Practices for Chunking\n",
    "- **Consistency**: Maintain uniform chunk sizes where possible.\n",
    "- **Contextual Integrity**: Ensure chunks are self-contained to preserve meaning.\n",
    "\n",
    "### Different Types of Chunking\n",
    "- **Sentence-level**: Ideal for fine-grained analysis or retrieval.\n",
    "- **Paragraph-level**: Balances granularity with context preservation.\n",
    "- **Section-level**: Useful for documents with clear structural delineations.\n",
    "\n",
    "### Mega Chunking Strategy\n",
    "Mega chunking involves grouping related smaller chunks into larger units for purposes like summarization or when a broader context is necessary for understanding.\n",
    "\n",
    "### Creating Chunks and Mega Chunks\n",
    "We will explore methods to programmatically segment our documents into chunks and group these into mega chunks, according to our predefined strategies.\n",
    "\n",
    "### Summarizing Mega Chunks\n",
    "Summarization techniques applied to mega chunks will be demonstrated to condense the information content, facilitating quicker comprehension by the RAG system.\n",
    "\n",
    "## 3. DB Setup and Insertion\n",
    "\n",
    "### How to Set Up a Database for Fast Retrieval\n",
    "Efficient database setup is essential for minimizing retrieval times and enhancing the overall performance of the RAG system.\n",
    "\n",
    "### How to Store Embeddings and Metadata\n",
    "We discuss strategies for storing embeddings alongside rich metadata to facilitate effective retrieval and relevance determination.\n",
    "\n",
    "### Creating FAISS Vectorstore\n",
    "\n",
    "#### What is FAISS\n",
    "FAISS (Facebook AI Similarity Search) is a library for efficient similarity search and clustering of dense vectors. It excels in large-scale vector storage and quick nearest neighbor retrieval.\n",
    "\n",
    "#### Different Types of FAISS Index\n",
    "- **Flat (L2) Index**: Offers exact nearest neighbor search.\n",
    "- **HNSW Index**: Provides a balance between speed and accuracy for approximate searches.\n",
    "\n",
    "#### Creating L2 and HNSW Indexes\n",
    "Step-by-step guidance on setting up L2 and HNSW indexes in FAISS, tailored for different retrieval needs.\n",
    "\n",
    "### Creating MongoDB Collection (Metadata)\n",
    "\n",
    "#### What Type of Metadata We Want to Store\n",
    "Discussing the importance of various metadata fields in enhancing document retrieval and understanding.\n",
    "\n",
    "#### Document Metadata Information (Mongo)\n",
    "- **document_name**\n",
    "- **document_word_count**\n",
    "- **page_number**\n",
    "- **page_word_count**\n",
    "- **page_sentence_count**\n",
    "- **page_token_count**\n",
    "- **text**\n",
    "\n",
    "This section outlines the process of creating a MongoDB collection to store the aforementioned metadata, ensuring that each document and its chunks are easily retrievable and\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, we understood the Project Overview, fetched and preprocessed our Documents.\n",
    "Now In this Notebook, let us understand what are the best ways of Using these Documents to answer Queries using a Large Language Model.\n",
    "Let us cover and understand the below points:\n",
    "\n",
    "- 1. Embeddings\n",
    "    - What is an Embedding and why we need them?\n",
    "    - Things to keep in mind while creating Embeddings\n",
    "    - Strategies for Creating Embeddings\n",
    "    - MTEB Leaderboard\n",
    "    - **Creating Embeddings**\n",
    "    - How Embeddings impact the performance of RAG System.\n",
    "    \n",
    "- 2. Chunking Text\n",
    "    - Why we Need Chunks?\n",
    "    - What are the Best Practices for Chunking?\n",
    "    - Different Types of Chunking\n",
    "    - *Mega Chunking* Strategy\n",
    "    - **Creating Chunks and Mega Chunks**\n",
    "    - **Summarizing Mega chunks**\n",
    "- 3. DB Setup and Insertion\n",
    "    - How do setup a Database for Fast Retrieval\n",
    "    - How to store Embeddings and Metadata\n",
    "    - Creating FAISS Vectorstore\n",
    "        - What is FAISS\n",
    "        - Different types of FAISS Index\n",
    "        - Creating L2 Index\n",
    "        - Creating HNSW Index\n",
    "    - Creating Mongo DB Collection (Metadata)\n",
    "        - What Type of metadata we want to store\n",
    "        - Document Metadata Information: (Mongo)\n",
    "            - document_name\n",
    "            - document_word_count\n",
    "            - page_number\n",
    "            - page_word_count\n",
    "            - page_sentence_count\n",
    "            - page_token_count\n",
    "            - text\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers the Chunking Strategies used in a RAG Pipeline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Overlap Chunking\n",
    "-- CharacterSplitter \n",
    "- Chunk Lacks Global Concept Awareness -> Sub Document Summaries\n",
    "    - A Context Augmentation Technique.\n",
    "    - Along with Chunk, we can summarize the whole document, and attach that summary along with it as metadata to each embedding.\n",
    "    - This may not solve the problem completely, as each chunk can have a \"local Context\". For Example, a document on Sachin Tendulkar  can have various parts which focus on different aspects of his life.\n",
    "    - So We can have sub-summaries. Different parts of document can summarised together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Size of Chunk must be < # Token in EMbedding Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the document into smaller managable chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SubDoc Summary - Divide the document in Sub Documents and then create a summary of each sub document.\n",
    "\n",
    "\n",
    "So Lets say if a Document has 100 chunks\n",
    "now lets combine 20 chunks and summarize them..\n",
    "- User query will go to SubDocument Summary to get a chunk, then it will go the chunks which have that information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is a trade-off\n",
    "    - smaller chunks -> Higher Accuracy, more chunks\n",
    "    - bigger chunks -> Lesser Accuracy, easy handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking Strategy:\n",
    "- Each Document will be divided into chunks of 300 character with 50 overlap.\n",
    "- 10 chunks will be combined to create a summary_chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Document Metadata Information: (Mongo)\n",
    "    - document_name\n",
    "    - document_word_count\n",
    "    - page_number\n",
    "    - page_word_count\n",
    "    - page_sentence_count\n",
    "    - page_token_count\n",
    "    - text\n",
    "    \n",
    "- chunk_metadata\n",
    "    - document_metadata +\n",
    "    - chunk_text\n",
    "    -  summary_chunk_text\n",
    "    - FAISS_SUMMARY_CHUNK_INDEX (PK)\n",
    "    - FAISS_CHUNK_INDEX_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load Environment Variables\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(Path('C:/Users/erdrr/OneDrive/Desktop/Scholastic/NLP/LLM/RAG/CompleteRAG/.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import unicodedata\n",
    "from time import perf_counter as timer\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import fitz\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from src.embeddings.models import summarize_mega_chunk,get_embedding_model\n",
    "from src.embeddings.vectorstore import add_faiss_indices_to_dataframe\n",
    "from src.embeddings.database import insert_into_mongodb\n",
    "load_dotenv(Path('C:/Users/erdrr/OneDrive/Desktop/Scholastic/NLP/LLM/RAG/CompleteRAG/.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/erdrr/OneDrive/Desktop/Scholastic/NLP/LLM/RAG/CompleteRAG/data/preprocessed')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data_path = Path(os.environ[\"PREPROCESSED_DATA_DIR\"])\n",
    "preprocessed_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_pagewise_data(file_path:Path):\n",
    "    doc = fitz.open(file_path)\n",
    "    pagewise_data = []\n",
    "    text=\" \"\n",
    "    document_text = \" \"\n",
    "    for num,page in tqdm(enumerate(doc)):\n",
    "        text = page.get_text().replace(\"\\n\",\" \").strip()\n",
    "        normalized_text = unicodedata.normalize('NFKD', text)\n",
    "        text = normalized_text.encode('ascii', 'ignore').decode('ascii')\n",
    "        document_text += text + \" \"\n",
    "        pagewise_data.append({\n",
    "            \"page_number\": num + 1,\n",
    "            \"page_char_count\": len(text),\n",
    "            \"page_word_count\": len(text.split(\" \")),\n",
    "            \"page_sentence_count\": len(text.split(\". \")),\n",
    "            \"page_token_count\": len(text) // 4,\n",
    "            \"page_text\": text,\n",
    "            \"document_name\": os.path.basename(file_path).replace(\".pdf\",\"\")\n",
    "            })\n",
    "    doc.close()\n",
    "    ## Add Document Level Metadata\n",
    "    for doc in pagewise_data:\n",
    "        doc[\"document_word_count\"] = len(document_text)\n",
    "        doc[\"document_page_count\"] = num + 1\n",
    "    return pagewise_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_documents_data(documents_dir_path : Path=preprocessed_data_path):\n",
    "    all_documents_data = []\n",
    "    docs_list = os.listdir(documents_dir_path)[40:80]\n",
    "    for item in tqdm(docs_list):\n",
    "        file_path = Path(os.path.join(preprocessed_data_path,item))\n",
    "        all_documents_data.append(get_document_pagewise_data(file_path))\n",
    "    \n",
    "    # Flatten the list\n",
    "    flattened_list = []\n",
    "    for sublist in all_documents_data:\n",
    "        # Loop through each dictionary in the inner lists and add it to the flattened_list\n",
    "        for d in sublist:\n",
    "            flattened_list.append(d)\n",
    "    return flattened_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c39e596edc74133ba6175e0f0a90b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82857b0f7522497ebc0174c57c847adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9963cbe354714e6d9b3f1f31699dba64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e97e49aaae402d94eec695800fe5a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c42922c5d674362acb6896ae6da073e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3608f731d03b44e0928823141a92ff5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e8b3274ad64b249c9b481c4619396b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2426d76270f8409483e6487ac5c95b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cf9b62230a46ef817ecfc38cb7dd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61207cbc78a4cdcacaef5b2520e1931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9bc2d1ce9654bd9a8d210e78382d1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927cf624162e47d19420a7154e906785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9aeb8f0dbe4234a8e78a8c0582e6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2749f9da234cab9de26c4af144f2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb14865b85224970ace2708a751a0486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c46601304d748e78e864f4a792a833a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ab9b642ec44a6091b3e4eb39cc4a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd071a01bc2f4759a9303860ce11dbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c650b26a04463c9909ee418ad7141b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db331d3ae14b43008cfd68fbffd81eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d106416a9886483dbd1b2bcbe5875dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af06c41bbcfc4d32824118ceb9eb14e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede72cc97c844d998ac8e066d4093bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e8b4a10e294841b183384137f39eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a97201a525405d8e28ea57c4ef8d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5dd014509144ff910e2db62f1bc89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91494d34e11248d28ff35cae5dd4b1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d5867ae6bd4d329c1071741365b21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d9b5018e58449e9e17b3ad8a478866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10775bf1be0848489e6bb2ed6f9078b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13dfb7e78b9242b3849e65010c7b42d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af60b424a1bd4203ab09c8a52b308aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575d80a813234300a7bb65816cf4df4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933c07e1ea384a3db90d7a3027729c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d230b456ec9428985d799a676bc5081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e7e479efc2404aaf483224efa66823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634f6d837dc3478e9bb94cc558885815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f4ce14d612434ab54636d35c7709e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5148ea56282747ec891dcb16e67f7706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8258778019c45bcb65a4bfaf0d7e7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761fb0bdeff746b98effcab9de716384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_documents_data = get_all_documents_data(preprocessed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df = pd.DataFrame(all_documents_data)\n",
    "all_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>document_word_count</th>\n",
       "      <th>document_page_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.492537</td>\n",
       "      <td>3971.253731</td>\n",
       "      <td>651.492537</td>\n",
       "      <td>30.492537</td>\n",
       "      <td>992.462687</td>\n",
       "      <td>7903.014925</td>\n",
       "      <td>1.985075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.682534</td>\n",
       "      <td>1685.696613</td>\n",
       "      <td>277.447040</td>\n",
       "      <td>14.044705</td>\n",
       "      <td>421.436732</td>\n",
       "      <td>3688.485229</td>\n",
       "      <td>0.807025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3033.500000</td>\n",
       "      <td>493.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>758.000000</td>\n",
       "      <td>5156.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4976.000000</td>\n",
       "      <td>788.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1244.000000</td>\n",
       "      <td>7033.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5296.500000</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1323.500000</td>\n",
       "      <td>10298.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>5473.000000</td>\n",
       "      <td>977.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1368.000000</td>\n",
       "      <td>16852.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count  \\\n",
       "count    67.000000        67.000000        67.000000            67.000000   \n",
       "mean      1.492537      3971.253731       651.492537            30.492537   \n",
       "std       0.682534      1685.696613       277.447040            14.044705   \n",
       "min       1.000000        11.000000         1.000000             1.000000   \n",
       "25%       1.000000      3033.500000       493.500000            20.000000   \n",
       "50%       1.000000      4976.000000       788.000000            35.000000   \n",
       "75%       2.000000      5296.500000       857.000000            40.000000   \n",
       "max       4.000000      5473.000000       977.000000            50.000000   \n",
       "\n",
       "       page_token_count  document_word_count  document_page_count  \n",
       "count         67.000000            67.000000            67.000000  \n",
       "mean         992.462687          7903.014925             1.985075  \n",
       "std          421.436732          3688.485229             0.807025  \n",
       "min            2.000000          1863.000000             1.000000  \n",
       "25%          758.000000          5156.000000             1.000000  \n",
       "50%         1244.000000          7033.000000             2.000000  \n",
       "75%         1323.500000         10298.000000             2.000000  \n",
       "max         1368.000000         16852.000000             4.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Using chunk_size=300 | chunk_overlap=50 | mega_chunk_multiplier=10\n"
     ]
    }
   ],
   "source": [
    "chunk_size = int(os.environ[\"CHUNK_SIZE\"])\n",
    "chunk_overlap = int(os.environ[\"CHUNK_OVERLAP_SIZE\"])\n",
    "mega_chunk_multiplier = int(os.environ[\"MEGA_CHUNK_MULTIPLIER\"])\n",
    "print(f\"[INFO]: Using {chunk_size=} | {chunk_overlap=} | {mega_chunk_multiplier=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlap(str1: str, str2: str) -> int:\n",
    "    \"\"\"\n",
    "    Finds the length of the largest overlap between the end of str1 and the start of str2.\n",
    "    \n",
    "    Parameters:\n",
    "    - str1 (str): The first string.\n",
    "    - str2 (str): The second string.\n",
    "    \n",
    "    Returns:\n",
    "    - int: The length of the overlap.\n",
    "    \"\"\"\n",
    "    min_length = min(len(str1), len(str2))\n",
    "    for i in range(1, min_length + 1):\n",
    "        if str1[-i:] == str2[:i]:\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "def combine_strings_remove_overlap(str_list: list) -> str:\n",
    "    \"\"\"\n",
    "    Combines a list of strings by removing overlapping text.\n",
    "    \n",
    "    Parameters:\n",
    "    - str_list (list): A list of strings with possible overlaps.\n",
    "    \n",
    "    Returns:\n",
    "    - str: A single combined string with overlaps removed.\n",
    "    \"\"\"\n",
    "    if not str_list:\n",
    "        return \"\"\n",
    "\n",
    "    # Initialize the combined string with the first string in the list\n",
    "    combined_string = str_list[0]\n",
    "\n",
    "    # Iterate through the list, combining strings with overlap removed\n",
    "    for i in range(1, len(str_list)):\n",
    "        overlap_length = find_overlap(combined_string, str_list[i])\n",
    "        combined_string += str_list[i][overlap_length:]\n",
    "\n",
    "    return combined_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def create_chunks(df,\n",
    "                  chunk_size: int = int(os.environ.get(\"CHUNK_SIZE\", 256)),\n",
    "                  chunk_overlap: int = int(os.environ.get(\"CHUNK_OVERLAP_SIZE\", 50)),\n",
    "                  mega_chunk_multiplier: int = int(os.environ.get(\"MEGA_CHUNK_MULTIPLIER\", 4))):\n",
    "    print(f\"[INFO]: Creating Chunks Using: chunk_size={chunk_size} | chunk_overlap={chunk_overlap} | mega_chunk_multiplier={mega_chunk_multiplier}\")\n",
    "\n",
    "    # Assuming RecursiveCharacterTextSplitter is implemented correctly\n",
    "    chunk_text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "    # Split text into chunks\n",
    "    df['chunks'] = df['page_text'].apply(lambda x: chunk_text_splitter.split_text(x))\n",
    "\n",
    "    # Create a list of mega chunks, each with its constituent chunks\n",
    "    def create_mega_chunks_with_chunks(chunks, multiplier):\n",
    "        mega_chunks_with_chunks = []\n",
    "        for i in range(0, len(chunks), multiplier):\n",
    "            mega_chunk_with_chunks = chunks[i:i + multiplier]\n",
    "            mega_chunks_with_chunks.append({'mega_chunk': ''.join(mega_chunk_with_chunks), 'chunks': mega_chunk_with_chunks})\n",
    "        return mega_chunks_with_chunks\n",
    "\n",
    "    df['mega_chunks_with_chunks'] = df['chunks'].apply(lambda x: create_mega_chunks_with_chunks(x, mega_chunk_multiplier))\n",
    "    \n",
    "    # Explode DataFrame by 'mega_chunks_with_chunks'\n",
    "    df = df.explode('mega_chunks_with_chunks').reset_index(drop=True)\n",
    "    \n",
    "    # Extract 'mega_chunk' and 'chunks' from the exploded dictionaries\n",
    "    df['mega_chunk'] = df['mega_chunks_with_chunks'].apply(lambda x: x['mega_chunk'])\n",
    "    df['chunks_in_mega'] = df['mega_chunks_with_chunks'].apply(lambda x: x['chunks'])\n",
    "    \n",
    "    # Assign mega_chunk_number for enumeration within each document/page\n",
    "    df['mega_chunk_number'] = df.groupby(['document_name', 'page_number']).cumcount() + 1\n",
    "\n",
    "    # Calculate the number of mega chunks per page\n",
    "    df['page_mega_chunk_count'] = df.groupby(['document_name', 'page_number'])['mega_chunk_number'].transform('max')\n",
    "\n",
    "    # Specify columns to include in the final DataFrame\n",
    "    df_columns = ['document_name', 'document_word_count', 'document_page_count', 'page_number', 'page_char_count', 'page_word_count',\n",
    "                  'page_sentence_count', 'page_token_count', 'page_text', 'page_mega_chunk_count', 'mega_chunk_number', 'mega_chunk', 'chunks_in_mega']\n",
    "    df = df[df_columns]\n",
    "    df_final = df.rename(columns={'chunks_in_mega': 'chunks'})\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Creating Chunks Using: chunk_size=300 | chunk_overlap=50 | mega_chunk_multiplier=10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>document_word_count</th>\n",
       "      <th>document_page_count</th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_text</th>\n",
       "      <th>page_mega_chunk_count</th>\n",
       "      <th>mega_chunk_number</th>\n",
       "      <th>mega_chunk</th>\n",
       "      <th>chunksa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Investopedia_1_What_Is_3_2_1_Buydown</td>\n",
       "      <td>7033</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5320</td>\n",
       "      <td>932</td>\n",
       "      <td>40</td>\n",
       "      <td>1330</td>\n",
       "      <td>A 3-2-1 buydown mortgage is a type of home loa...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A 3-2-1 buydown mortgage is a type of home loa...</td>\n",
       "      <td>[A 3-2-1 buydown mortgage is a type of home lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investopedia_1_What_Is_3_2_1_Buydown</td>\n",
       "      <td>7033</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5320</td>\n",
       "      <td>932</td>\n",
       "      <td>40</td>\n",
       "      <td>1330</td>\n",
       "      <td>A 3-2-1 buydown mortgage is a type of home loa...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>future years. Over the first three years of lo...</td>\n",
       "      <td>[future years. Over the first three years of l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Investopedia_1_What_Is_3_2_1_Buydown</td>\n",
       "      <td>7033</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5320</td>\n",
       "      <td>932</td>\n",
       "      <td>40</td>\n",
       "      <td>1330</td>\n",
       "      <td>A 3-2-1 buydown mortgage is a type of home loa...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>such as investing it or using it to pay off ot...</td>\n",
       "      <td>[such as investing it or using it to pay off o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Investopedia_1_What_Is_3_2_1_Buydown</td>\n",
       "      <td>7033</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1710</td>\n",
       "      <td>296</td>\n",
       "      <td>12</td>\n",
       "      <td>427</td>\n",
       "      <td>even then, ask yourself whether the maximum mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>even then, ask yourself whether the maximum mo...</td>\n",
       "      <td>[even then, ask yourself whether the maximum m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Investopedia_1_What_Is_3_6_3_Rule</td>\n",
       "      <td>5299</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5271</td>\n",
       "      <td>850</td>\n",
       "      <td>32</td>\n",
       "      <td>1317</td>\n",
       "      <td>What Is the 3-6-3 Rule? The 3-6-3 rule is a sl...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>What Is the 3-6-3 Rule? The 3-6-3 rule is a sl...</td>\n",
       "      <td>[What Is the 3-6-3 Rule? The 3-6-3 rule is a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Investopedia_A_What_Is_Absoluteadvantage</td>\n",
       "      <td>10621</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5343</td>\n",
       "      <td>873</td>\n",
       "      <td>35</td>\n",
       "      <td>1335</td>\n",
       "      <td>disasters, for example, can destroy farmland, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>bacon. Pacifica can spend one-third of the yea...</td>\n",
       "      <td>[bacon. Pacifica can spend one-third of the ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Investopedia_A_What_Is_Absoluteadvantage</td>\n",
       "      <td>10621</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5343</td>\n",
       "      <td>873</td>\n",
       "      <td>35</td>\n",
       "      <td>1335</td>\n",
       "      <td>disasters, for example, can destroy farmland, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>represents Adam Smith's explanation of why cou...</td>\n",
       "      <td>[represents Adam Smith's explanation of why co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Investopedia_A_What_Is_Absoluteadvantage</td>\n",
       "      <td>10621</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>advantages.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>advantages.</td>\n",
       "      <td>[advantages.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Investopedia_A_What_Is_Absolutereturn</td>\n",
       "      <td>3342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3340</td>\n",
       "      <td>544</td>\n",
       "      <td>26</td>\n",
       "      <td>835</td>\n",
       "      <td>What Is Absolute Return? Absolute return is th...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>What Is Absolute Return? Absolute return is th...</td>\n",
       "      <td>[What Is Absolute Return? Absolute return is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Investopedia_A_What_Is_Absolutereturn</td>\n",
       "      <td>3342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3340</td>\n",
       "      <td>544</td>\n",
       "      <td>26</td>\n",
       "      <td>835</td>\n",
       "      <td>What Is Absolute Return? Absolute return is th...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>A hedge fund manager raises funds by working w...</td>\n",
       "      <td>[A hedge fund manager raises funds by working ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                document_name  document_word_count  \\\n",
       "0        Investopedia_1_What_Is_3_2_1_Buydown                 7033   \n",
       "1        Investopedia_1_What_Is_3_2_1_Buydown                 7033   \n",
       "2        Investopedia_1_What_Is_3_2_1_Buydown                 7033   \n",
       "3        Investopedia_1_What_Is_3_2_1_Buydown                 7033   \n",
       "4           Investopedia_1_What_Is_3_6_3_Rule                 5299   \n",
       "..                                        ...                  ...   \n",
       "146  Investopedia_A_What_Is_Absoluteadvantage                10621   \n",
       "147  Investopedia_A_What_Is_Absoluteadvantage                10621   \n",
       "148  Investopedia_A_What_Is_Absoluteadvantage                10621   \n",
       "149     Investopedia_A_What_Is_Absolutereturn                 3342   \n",
       "150     Investopedia_A_What_Is_Absolutereturn                 3342   \n",
       "\n",
       "     document_page_count  page_number  page_char_count  page_word_count  \\\n",
       "0                      2            1             5320              932   \n",
       "1                      2            1             5320              932   \n",
       "2                      2            1             5320              932   \n",
       "3                      2            2             1710              296   \n",
       "4                      2            1             5271              850   \n",
       "..                   ...          ...              ...              ...   \n",
       "146                    3            2             5343              873   \n",
       "147                    3            2             5343              873   \n",
       "148                    3            3               11                1   \n",
       "149                    1            1             3340              544   \n",
       "150                    1            1             3340              544   \n",
       "\n",
       "     page_sentence_count  page_token_count  \\\n",
       "0                     40              1330   \n",
       "1                     40              1330   \n",
       "2                     40              1330   \n",
       "3                     12               427   \n",
       "4                     32              1317   \n",
       "..                   ...               ...   \n",
       "146                   35              1335   \n",
       "147                   35              1335   \n",
       "148                    1                 2   \n",
       "149                   26               835   \n",
       "150                   26               835   \n",
       "\n",
       "                                             page_text  page_mega_chunk_count  \\\n",
       "0    A 3-2-1 buydown mortgage is a type of home loa...                      3   \n",
       "1    A 3-2-1 buydown mortgage is a type of home loa...                      3   \n",
       "2    A 3-2-1 buydown mortgage is a type of home loa...                      3   \n",
       "3    even then, ask yourself whether the maximum mo...                      1   \n",
       "4    What Is the 3-6-3 Rule? The 3-6-3 rule is a sl...                      3   \n",
       "..                                                 ...                    ...   \n",
       "146  disasters, for example, can destroy farmland, ...                      3   \n",
       "147  disasters, for example, can destroy farmland, ...                      3   \n",
       "148                                        advantages.                      1   \n",
       "149  What Is Absolute Return? Absolute return is th...                      2   \n",
       "150  What Is Absolute Return? Absolute return is th...                      2   \n",
       "\n",
       "     mega_chunk_number                                         mega_chunk  \\\n",
       "0                    1  A 3-2-1 buydown mortgage is a type of home loa...   \n",
       "1                    2  future years. Over the first three years of lo...   \n",
       "2                    3  such as investing it or using it to pay off ot...   \n",
       "3                    1  even then, ask yourself whether the maximum mo...   \n",
       "4                    1  What Is the 3-6-3 Rule? The 3-6-3 rule is a sl...   \n",
       "..                 ...                                                ...   \n",
       "146                  2  bacon. Pacifica can spend one-third of the yea...   \n",
       "147                  3  represents Adam Smith's explanation of why cou...   \n",
       "148                  1                                        advantages.   \n",
       "149                  1  What Is Absolute Return? Absolute return is th...   \n",
       "150                  2  A hedge fund manager raises funds by working w...   \n",
       "\n",
       "                                               chunksa  \n",
       "0    [A 3-2-1 buydown mortgage is a type of home lo...  \n",
       "1    [future years. Over the first three years of l...  \n",
       "2    [such as investing it or using it to pay off o...  \n",
       "3    [even then, ask yourself whether the maximum m...  \n",
       "4    [What Is the 3-6-3 Rule? The 3-6-3 rule is a s...  \n",
       "..                                                 ...  \n",
       "146  [bacon. Pacifica can spend one-third of the ye...  \n",
       "147  [represents Adam Smith's explanation of why co...  \n",
       "148                                      [advantages.]  \n",
       "149  [What Is Absolute Return? Absolute return is t...  \n",
       "150  [A hedge fund manager raises funds by working ...  \n",
       "\n",
       "[151 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_chunks(all_data_df)#.to_json(\"test.json\",orient=\"records\",indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save our Embeddings, we need a Vector Database, which can store our 1x1024 dimensional vector Embeddings. When a User queries, we need to convert the user query to an Embedding and serch in out Vector Database. There are vaious Vectro Databases Available, but we will be using FAISS Library from Facebook to store our Vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAISS (Facebook AI Similarity Search) is a library developed by Facebook AI Research to facilitate efficient similarity search and clustering of dense vectors. It's widely used for tasks such as image retrieval, recommendation systems, and natural language processing where finding nearest neighbors in high-dimensional spaces is required. FAISS is designed to be highly efficient both in terms of speed and memory usage for vector search operations. It supports various index types, each optimized for different use cases and trade-offs between speed, accuracy, and memory usage. Here are the main types of indexes in FAISS:\n",
    "\n",
    "1. **Flat Indexes (IndexFlat)**: These are the simplest form of indexes in FAISS, where the database vectors are stored as they are, without any encoding or compression. Searches in flat indexes involve comparing the query vector with every vector in the database, which is computationally expensive but provides the exact nearest neighbors. Flat indexes are often used as benchmarks for accuracy.\n",
    "\n",
    "2. **Quantization-based Indexes**:\n",
    "   - **IndexIVFFlat**: This index uses an Inverted File system (IVF) with flat encoding. It divides the vector space into a finite number of coarse quantization regions (clusters) and assigns each vector to its nearest cluster. Searches are accelerated by only considering vectors in the nearest clusters to the query vector.\n",
    "   - **IndexIVFPQ**: Similar to IndexIVFFlat, but within each cluster, it applies Product Quantization (PQ) for further compression and faster search. PQ decomposes the space into a Cartesian product of subspaces and quantizes each subspace separately.\n",
    "   - **IndexIVFScalarQuantizer**: This index also uses IVF clustering but employs scalar quantization for the vectors within each cluster, offering a trade-off between memory usage and accuracy.\n",
    "\n",
    "3. **Hierarchical Navigable Small World (HNSW) Indexes (IndexHNSW)**: HNSW indexes are graph-based and excel in providing a good balance between search speed and accuracy, especially for very high-dimensional data. They build a multi-layered graph structure that allows for efficient greedy searches.\n",
    "\n",
    "4. **Binary Indexes (IndexBinaryFlat, IndexBinaryIVF, etc.)**: These indexes are designed for binary vectors (vectors of 0s and 1s) and use specialized distance measures like Hamming distance. They are useful for applications where data is naturally binary or has been binarized.\n",
    "\n",
    "5. **Composite Indexes**:\n",
    "   - **IndexIDMap**: This is a wrapper that allows any index to store arbitrary IDs for each vector, facilitating easy retrieval of original identifiers after search operations.\n",
    "   - **IndexPreTransform**: This index applies a transformation (e.g., PCA, whitening) to vectors before indexing them with another index type, which can improve search performance and accuracy.\n",
    "\n",
    "6. **GPU Indexes (GpuIndexFlat, GpuIndexIVFFlat, etc.)**: FAISS provides GPU versions for many of its indexes, enabling significantly faster search speeds by leveraging the parallel processing power of GPUs.\n",
    "\n",
    "Each index type in FAISS serves different needs, ranging from exact searches to approximate searches that prioritize speed or memory efficiency. The choice of index depends on the specific requirements of the application, such as the size of the dataset, the dimensionality of the vectors, the acceptable trade-off between accuracy and speed, and the available computational resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataframe to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = Path(os.environ[\"PROCESSED_DATA_DIR\"])\n",
    "json_file_path = os.path.join(processed_data_path,\"all_chunks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(json_file_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>document_word_count</th>\n",
       "      <th>document_page_count</th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_text</th>\n",
       "      <th>mega_chunk</th>\n",
       "      <th>mega_chunk_summary</th>\n",
       "      <th>mega_chunk_summary_embedding_index</th>\n",
       "      <th>chunks</th>\n",
       "      <th>chunks_embedding_list_index</th>\n",
       "      <th>_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Investopedia_012715_What_Is_5_Richest_People_W...</td>\n",
       "      <td>17922</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5358</td>\n",
       "      <td>892</td>\n",
       "      <td>45</td>\n",
       "      <td>1339</td>\n",
       "      <td>Billionaires play an outsized role in shaping ...</td>\n",
       "      <td>Billionaires play an outsized role in shaping ...</td>\n",
       "      <td>Forbes puts the number of billionaires in the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Billionaires play an outsized role in shaping...</td>\n",
       "      <td>[6627, 6628, 6629, 6630, 6631, 6632, 6633, 663...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investopedia_012715_What_Is_5_Richest_People_W...</td>\n",
       "      <td>17922</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5358</td>\n",
       "      <td>892</td>\n",
       "      <td>45</td>\n",
       "      <td>1339</td>\n",
       "      <td>Billionaires play an outsized role in shaping ...</td>\n",
       "      <td>500 , becoming the largest company added, and ...</td>\n",
       "      <td>In April 2022, Musk began a campaign to take X...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Billionaires play an outsized role in shaping...</td>\n",
       "      <td>[6649, 6650, 6651, 6652, 6653, 6654, 6655, 665...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Investopedia_012715_What_Is_5_Richest_People_W...</td>\n",
       "      <td>17922</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5308</td>\n",
       "      <td>832</td>\n",
       "      <td>44</td>\n",
       "      <td>1327</td>\n",
       "      <td>10,000-year clockalso known as the Long Now. O...</td>\n",
       "      <td>10,000-year clockalso known as the Long Now. O...</td>\n",
       "      <td>Bezos' wealth peaked at $213 billion in the sa...</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,000-year clockalso known as the Long Now. ...</td>\n",
       "      <td>[6671, 6672, 6673, 6674, 6675, 6676, 6677, 667...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Investopedia_012715_What_Is_5_Richest_People_W...</td>\n",
       "      <td>17922</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5308</td>\n",
       "      <td>832</td>\n",
       "      <td>44</td>\n",
       "      <td>1327</td>\n",
       "      <td>10,000-year clockalso known as the Long Now. O...</td>\n",
       "      <td>seeks to leverage technology to fix societal i...</td>\n",
       "      <td>Bill Gates is the co-founder of Microsoft, the...</td>\n",
       "      <td>3</td>\n",
       "      <td>[10,000-year clockalso known as the Long Now. ...</td>\n",
       "      <td>[6692, 6693, 6694, 6695, 6696, 6697, 6698, 669...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Investopedia_012715_What_Is_5_Richest_People_W...</td>\n",
       "      <td>17922</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5210</td>\n",
       "      <td>831</td>\n",
       "      <td>45</td>\n",
       "      <td>1302</td>\n",
       "      <td>2014, shortly after stepping down as Microsoft...</td>\n",
       "      <td>2014, shortly after stepping down as Microsoft...</td>\n",
       "      <td>Ballmer lived in the same dorm and on the same...</td>\n",
       "      <td>4</td>\n",
       "      <td>[2014, shortly after stepping down as Microsof...</td>\n",
       "      <td>[6713, 6714, 6715, 6716, 6717, 6718, 6719, 672...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6622</th>\n",
       "      <td>Investopedia_G_What_Is_G_30</td>\n",
       "      <td>5007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5005</td>\n",
       "      <td>803</td>\n",
       "      <td>32</td>\n",
       "      <td>1251</td>\n",
       "      <td>What Is the Group of 30 (G-30)? The Group of 3...</td>\n",
       "      <td>What Is the Group of 30 (G-30)? The Group of 3...</td>\n",
       "      <td>The Group of 30 (G-30) is a nonprofit group of...</td>\n",
       "      <td>6622</td>\n",
       "      <td>[What Is the Group of 30 (G-30)? The Group of ...</td>\n",
       "      <td>[122830, 122831, 122832, 122833, 122834, 12283...</td>\n",
       "      <td>6622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6623</th>\n",
       "      <td>Investopedia_G_What_Is_G_30</td>\n",
       "      <td>5007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5005</td>\n",
       "      <td>803</td>\n",
       "      <td>32</td>\n",
       "      <td>1251</td>\n",
       "      <td>What Is the Group of 30 (G-30)? The Group of 3...</td>\n",
       "      <td>Witteveen, the former managing director of the...</td>\n",
       "      <td>The Group of 30 (G-30) is a group of 10 nation...</td>\n",
       "      <td>6623</td>\n",
       "      <td>[What Is the Group of 30 (G-30)? The Group of ...</td>\n",
       "      <td>[122850, 122851, 122852, 122853, 122854, 12285...</td>\n",
       "      <td>6623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6624</th>\n",
       "      <td>Investopedia_G_What_Is_Soros</td>\n",
       "      <td>5842</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5300</td>\n",
       "      <td>892</td>\n",
       "      <td>39</td>\n",
       "      <td>1325</td>\n",
       "      <td>George Soros is a legendary hedge fund manager...</td>\n",
       "      <td>George Soros is a legendary hedge fund manager...</td>\n",
       "      <td>Soros managed the Quantum Fund, a fund that ac...</td>\n",
       "      <td>6624</td>\n",
       "      <td>[George Soros is a legendary hedge fund manage...</td>\n",
       "      <td>[122870, 122871, 122872, 122873, 122874, 12287...</td>\n",
       "      <td>6624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6625</th>\n",
       "      <td>Investopedia_G_What_Is_Soros</td>\n",
       "      <td>5842</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5300</td>\n",
       "      <td>892</td>\n",
       "      <td>39</td>\n",
       "      <td>1325</td>\n",
       "      <td>George Soros is a legendary hedge fund manager...</td>\n",
       "      <td>European Union issue perpetual bonds , a metho...</td>\n",
       "      <td>George Soros is unique among highly successful...</td>\n",
       "      <td>6625</td>\n",
       "      <td>[George Soros is a legendary hedge fund manage...</td>\n",
       "      <td>[122892, 122893, 122894, 122895, 122896, 12289...</td>\n",
       "      <td>6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6626</th>\n",
       "      <td>Investopedia_G_What_Is_Soros</td>\n",
       "      <td>5842</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>539</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>fund that Soros advised. His knowledge of regi...</td>\n",
       "      <td>fund that Soros advised. His knowledge of regi...</td>\n",
       "      <td>Soros is known for making outsized bets agains...</td>\n",
       "      <td>6626</td>\n",
       "      <td>[fund that Soros advised. His knowledge of reg...</td>\n",
       "      <td>[122914, 122915]</td>\n",
       "      <td>6626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6627 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          document_name  document_word_count  \\\n",
       "0     Investopedia_012715_What_Is_5_Richest_People_W...                17922   \n",
       "1     Investopedia_012715_What_Is_5_Richest_People_W...                17922   \n",
       "2     Investopedia_012715_What_Is_5_Richest_People_W...                17922   \n",
       "3     Investopedia_012715_What_Is_5_Richest_People_W...                17922   \n",
       "4     Investopedia_012715_What_Is_5_Richest_People_W...                17922   \n",
       "...                                                 ...                  ...   \n",
       "6622                        Investopedia_G_What_Is_G_30                 5007   \n",
       "6623                        Investopedia_G_What_Is_G_30                 5007   \n",
       "6624                       Investopedia_G_What_Is_Soros                 5842   \n",
       "6625                       Investopedia_G_What_Is_Soros                 5842   \n",
       "6626                       Investopedia_G_What_Is_Soros                 5842   \n",
       "\n",
       "      document_page_count  page_number  page_char_count  page_word_count  \\\n",
       "0                       4            1             5358              892   \n",
       "1                       4            1             5358              892   \n",
       "2                       4            2             5308              832   \n",
       "3                       4            2             5308              832   \n",
       "4                       4            3             5210              831   \n",
       "...                   ...          ...              ...              ...   \n",
       "6622                    1            1             5005              803   \n",
       "6623                    1            1             5005              803   \n",
       "6624                    2            1             5300              892   \n",
       "6625                    2            1             5300              892   \n",
       "6626                    2            2              539               89   \n",
       "\n",
       "      page_sentence_count  page_token_count  \\\n",
       "0                      45              1339   \n",
       "1                      45              1339   \n",
       "2                      44              1327   \n",
       "3                      44              1327   \n",
       "4                      45              1302   \n",
       "...                   ...               ...   \n",
       "6622                   32              1251   \n",
       "6623                   32              1251   \n",
       "6624                   39              1325   \n",
       "6625                   39              1325   \n",
       "6626                    4               134   \n",
       "\n",
       "                                              page_text  \\\n",
       "0     Billionaires play an outsized role in shaping ...   \n",
       "1     Billionaires play an outsized role in shaping ...   \n",
       "2     10,000-year clockalso known as the Long Now. O...   \n",
       "3     10,000-year clockalso known as the Long Now. O...   \n",
       "4     2014, shortly after stepping down as Microsoft...   \n",
       "...                                                 ...   \n",
       "6622  What Is the Group of 30 (G-30)? The Group of 3...   \n",
       "6623  What Is the Group of 30 (G-30)? The Group of 3...   \n",
       "6624  George Soros is a legendary hedge fund manager...   \n",
       "6625  George Soros is a legendary hedge fund manager...   \n",
       "6626  fund that Soros advised. His knowledge of regi...   \n",
       "\n",
       "                                             mega_chunk  \\\n",
       "0     Billionaires play an outsized role in shaping ...   \n",
       "1     500 , becoming the largest company added, and ...   \n",
       "2     10,000-year clockalso known as the Long Now. O...   \n",
       "3     seeks to leverage technology to fix societal i...   \n",
       "4     2014, shortly after stepping down as Microsoft...   \n",
       "...                                                 ...   \n",
       "6622  What Is the Group of 30 (G-30)? The Group of 3...   \n",
       "6623  Witteveen, the former managing director of the...   \n",
       "6624  George Soros is a legendary hedge fund manager...   \n",
       "6625  European Union issue perpetual bonds , a metho...   \n",
       "6626  fund that Soros advised. His knowledge of regi...   \n",
       "\n",
       "                                     mega_chunk_summary  \\\n",
       "0     Forbes puts the number of billionaires in the ...   \n",
       "1     In April 2022, Musk began a campaign to take X...   \n",
       "2     Bezos' wealth peaked at $213 billion in the sa...   \n",
       "3     Bill Gates is the co-founder of Microsoft, the...   \n",
       "4     Ballmer lived in the same dorm and on the same...   \n",
       "...                                                 ...   \n",
       "6622  The Group of 30 (G-30) is a nonprofit group of...   \n",
       "6623  The Group of 30 (G-30) is a group of 10 nation...   \n",
       "6624  Soros managed the Quantum Fund, a fund that ac...   \n",
       "6625  George Soros is unique among highly successful...   \n",
       "6626  Soros is known for making outsized bets agains...   \n",
       "\n",
       "      mega_chunk_summary_embedding_index  \\\n",
       "0                                      0   \n",
       "1                                      1   \n",
       "2                                      2   \n",
       "3                                      3   \n",
       "4                                      4   \n",
       "...                                  ...   \n",
       "6622                                6622   \n",
       "6623                                6623   \n",
       "6624                                6624   \n",
       "6625                                6625   \n",
       "6626                                6626   \n",
       "\n",
       "                                                 chunks  \\\n",
       "0     [Billionaires play an outsized role in shaping...   \n",
       "1     [Billionaires play an outsized role in shaping...   \n",
       "2     [10,000-year clockalso known as the Long Now. ...   \n",
       "3     [10,000-year clockalso known as the Long Now. ...   \n",
       "4     [2014, shortly after stepping down as Microsof...   \n",
       "...                                                 ...   \n",
       "6622  [What Is the Group of 30 (G-30)? The Group of ...   \n",
       "6623  [What Is the Group of 30 (G-30)? The Group of ...   \n",
       "6624  [George Soros is a legendary hedge fund manage...   \n",
       "6625  [George Soros is a legendary hedge fund manage...   \n",
       "6626  [fund that Soros advised. His knowledge of reg...   \n",
       "\n",
       "                            chunks_embedding_list_index   _id  \n",
       "0     [6627, 6628, 6629, 6630, 6631, 6632, 6633, 663...     0  \n",
       "1     [6649, 6650, 6651, 6652, 6653, 6654, 6655, 665...     1  \n",
       "2     [6671, 6672, 6673, 6674, 6675, 6676, 6677, 667...     2  \n",
       "3     [6692, 6693, 6694, 6695, 6696, 6697, 6698, 669...     3  \n",
       "4     [6713, 6714, 6715, 6716, 6717, 6718, 6719, 672...     4  \n",
       "...                                                 ...   ...  \n",
       "6622  [122830, 122831, 122832, 122833, 122834, 12283...  6622  \n",
       "6623  [122850, 122851, 122852, 122853, 122854, 12285...  6623  \n",
       "6624  [122870, 122871, 122872, 122873, 122874, 12287...  6624  \n",
       "6625  [122892, 122893, 122894, 122895, 122896, 12289...  6625  \n",
       "6626                                   [122914, 122915]  6626  \n",
       "\n",
       "[6627 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Investopedia_012715_What_Is_5_Richest_People_World.pdf'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_master[\"document_name\"][0]+\".pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_into_document_master(df):\n",
    "    client = MongoClient(os.environ[\"MONGODB_IP\"], int(os.environ[\"MONGODB_PORT\"]))\n",
    "    db = client[os.environ[\"MONGODB_DB\"]]\n",
    "    df = df[['document_name', 'document_word_count', 'document_page_count']].drop_duplicates()\n",
    "    collection = db[os.environ[\"MONGODB_DOCUMENTS_MASTER_COLLECTION\"]]\n",
    "    df['_id'] = df['document_name']+\".pdf\"\n",
    "    data_dict = df.to_dict(\"records\")\n",
    "    # Initialize counter for inserted documents\n",
    "    inserted_count = 0\n",
    "\n",
    "    # Insert documents only if they don't already exist\n",
    "    for document in data_dict:\n",
    "        if collection.count_documents({'_id': document['_id']}, limit=1) == 0:\n",
    "            collection.insert_one(document)\n",
    "            inserted_count += 1\n",
    "\n",
    "    # Logging the result\n",
    "    print(f\"[INFO]: Successfully inserted {inserted_count} new documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>document_word_count</th>\n",
       "      <th>document_page_count</th>\n",
       "      <th>_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Investopedia_012715_What_Is_5_Richest_People_W...</td>\n",
       "      <td>17922</td>\n",
       "      <td>4</td>\n",
       "      <td>Investopedia_012715_What_Is_5_Richest_People_W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Investopedia_03_What_Is_071603</td>\n",
       "      <td>6008</td>\n",
       "      <td>2</td>\n",
       "      <td>Investopedia_03_What_Is_071603.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Investopedia_042315_What_Is_How_Do_Prepaid_Deb...</td>\n",
       "      <td>5810</td>\n",
       "      <td>2</td>\n",
       "      <td>Investopedia_042315_What_Is_How_Do_Prepaid_Deb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Investopedia_05_What_Is_Economicmoat</td>\n",
       "      <td>7852</td>\n",
       "      <td>2</td>\n",
       "      <td>Investopedia_05_What_Is_Economicmoat.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Investopedia_063015_What_Is_What_Effective_Int...</td>\n",
       "      <td>9033</td>\n",
       "      <td>2</td>\n",
       "      <td>Investopedia_063015_What_Is_What_Effective_Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6613</th>\n",
       "      <td>Investopedia_G_What_Is_Guppy_Multiple_Moving_A...</td>\n",
       "      <td>7284</td>\n",
       "      <td>2</td>\n",
       "      <td>Investopedia_G_What_Is_Guppy_Multiple_Moving_A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616</th>\n",
       "      <td>Investopedia_G_What_Is_Gwei_Ethereum</td>\n",
       "      <td>6531</td>\n",
       "      <td>2</td>\n",
       "      <td>Investopedia_G_What_Is_Gwei_Ethereum.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6619</th>\n",
       "      <td>Investopedia_G_What_Is_G_20</td>\n",
       "      <td>7306</td>\n",
       "      <td>2</td>\n",
       "      <td>Investopedia_G_What_Is_G_20.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6622</th>\n",
       "      <td>Investopedia_G_What_Is_G_30</td>\n",
       "      <td>5007</td>\n",
       "      <td>1</td>\n",
       "      <td>Investopedia_G_What_Is_G_30.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6624</th>\n",
       "      <td>Investopedia_G_What_Is_Soros</td>\n",
       "      <td>5842</td>\n",
       "      <td>2</td>\n",
       "      <td>Investopedia_G_What_Is_Soros.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2143 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          document_name  document_word_count  \\\n",
       "0     Investopedia_012715_What_Is_5_Richest_People_W...                17922   \n",
       "7                        Investopedia_03_What_Is_071603                 6008   \n",
       "10    Investopedia_042315_What_Is_How_Do_Prepaid_Deb...                 5810   \n",
       "13                 Investopedia_05_What_Is_Economicmoat                 7852   \n",
       "16    Investopedia_063015_What_Is_What_Effective_Int...                 9033   \n",
       "...                                                 ...                  ...   \n",
       "6613  Investopedia_G_What_Is_Guppy_Multiple_Moving_A...                 7284   \n",
       "6616               Investopedia_G_What_Is_Gwei_Ethereum                 6531   \n",
       "6619                        Investopedia_G_What_Is_G_20                 7306   \n",
       "6622                        Investopedia_G_What_Is_G_30                 5007   \n",
       "6624                       Investopedia_G_What_Is_Soros                 5842   \n",
       "\n",
       "      document_page_count                                                _id  \n",
       "0                       4  Investopedia_012715_What_Is_5_Richest_People_W...  \n",
       "7                       2                 Investopedia_03_What_Is_071603.pdf  \n",
       "10                      2  Investopedia_042315_What_Is_How_Do_Prepaid_Deb...  \n",
       "13                      2           Investopedia_05_What_Is_Economicmoat.pdf  \n",
       "16                      2  Investopedia_063015_What_Is_What_Effective_Int...  \n",
       "...                   ...                                                ...  \n",
       "6613                    2  Investopedia_G_What_Is_Guppy_Multiple_Moving_A...  \n",
       "6616                    2           Investopedia_G_What_Is_Gwei_Ethereum.pdf  \n",
       "6619                    2                    Investopedia_G_What_Is_G_20.pdf  \n",
       "6622                    1                    Investopedia_G_What_Is_G_30.pdf  \n",
       "6624                    2                   Investopedia_G_What_Is_Soros.pdf  \n",
       "\n",
       "[2143 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Successfully inserted 0 new documents.\n"
     ]
    }
   ],
   "source": [
    "insert_into_document_master(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_chunk_mapping_collection(input_df):\n",
    "    \"\"\"\n",
    "    Transforms the DataFrame according to the specified operations for MongoDB insertion.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_df (pd.DataFrame): The input DataFrame with columns \n",
    "      'mega_chunk_summary_embedding_index' and 'chunks_embedding_list_index'.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Transformed DataFrame with self mapping and '_id' column.\n",
    "    \"\"\"\n",
    "    input_df = input_df[['chunks_embedding_list_index','mega_chunk_summary_embedding_index']]\n",
    "    # Explode the 'chunks_embedding_list' column\n",
    "    exploded_df = input_df.explode('chunks_embedding_list_index')\n",
    "    \n",
    "    # Add self-mapping rows by copying 'mega_chunk_summary_embedding' into a new row with the same value for '_id'\n",
    "    self_map_df = pd.DataFrame({\n",
    "        'mega_chunk_summary_embedding_index': input_df['mega_chunk_summary_embedding_index'],\n",
    "        'chunks_embedding_list_index': input_df['mega_chunk_summary_embedding_index']\n",
    "    })\n",
    "    \n",
    "    # Rename 'chunks_embedding_list' to '_id' in both DataFrames\n",
    "    exploded_df = exploded_df.rename(columns={'chunks_embedding_list_index': '_id'})\n",
    "    self_map_df = self_map_df.rename(columns={'chunks_embedding_list_index': '_id'})\n",
    "    \n",
    "    # Concatenate the exploded DataFrame with the self-mapping DataFrame\n",
    "    final_df = pd.concat([exploded_df, self_map_df], ignore_index=True)\n",
    "\n",
    "    # Convert all NumPy int64 types to Python native int types for MongoDB compatibility\n",
    "    final_df = final_df.applymap(lambda x: int(x) if isinstance(x, np.int64) else x)\n",
    "\n",
    "    # Insert into Mongo Collection\n",
    "    client = MongoClient(os.environ[\"MONGODB_IP\"], int(os.environ[\"MONGODB_PORT\"]))\n",
    "    \n",
    "    \n",
    "    ## Insert into Mongo Collection\n",
    "    client = MongoClient(os.environ[\"MONGODB_IP\"], int(os.environ[\"MONGODB_PORT\"]))\n",
    "    db = client[os.environ[\"MONGODB_DB\"]]\n",
    "    collection = db[os.environ[\"MONGODB_MAPPING_COLLECTION\"]]\n",
    "    data_dict = final_df.to_dict(\"records\")\n",
    "    collection.insert_many(data_dict)\n",
    "    print(f\"[INFO]: Successfully Inserted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_chunk_mapping_collection(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_into_mongodb(df):\n",
    "    client = MongoClient(os.environ[\"MONGODB_IP\"], int(os.environ[\"MONGODB_PORT\"]))\n",
    "    db = client[os.environ[\"MONGODB_DB\"]]\n",
    "    collection = db[os.environ[\"MONGODB_COLLECTION\"]]\n",
    "    df['_id'] = df['mega_chunk_summary_embedding_index']\n",
    "    data_dict = df.to_dict(\"records\")\n",
    "    collection.insert_many(data_dict)\n",
    "    print(f\"[INFO]: Successfully Inserted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_py310",
   "language": "python",
   "name": "rag_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
